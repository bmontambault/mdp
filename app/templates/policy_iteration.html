<html>

<head>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
</head>

<div class="nav">
  <a href="/">Home</a>
  <a href="/value_iteration">Value Iteration</a>
  <a class="active" href="/policy_iteration">Policy Iteration</a>
</div>

<div>
<h2>Policy Iteration</h2>

<p>Policy iteration involves alternating between two steps, policy evaluation and policy improvement, until the optimal policy converges. First we initialize a random policy for each state (left, right, up, down, stay). We then find the value function for each state following this policy by iteration until convergence:</p>
<div lang="latex">
V_{i+1}^{\pi}(s) = \sum_{s'}P(s, \pi(s), s')(R(s, \pi(s), s') + \gamma V_{i}^{\pi}(s'))
</div>

Once the value function has converged, we update the optimal policy:
<div lang="latex">
\pi(s) = \text{argmax}_{a} \left\{\sum_{s'}P(s, a, s')(R(s, a, s') + \gamma V^(s')) \right\}</div>
</div>

<p>
If the policy doesn't change, the algorithm has finished. If the policy does change, we go back to step one to find the new value function for the new policy.
</p>

</div>

<div>

	<p>
	In policy iteration we alternate between evaluating the value function given a fixed policy and updating the policy given the value function. 
	</p>

	<p>
	As an example we look at an environment where we recieve a reward of 1 in the states (0,0) and (3,3), and no reward in any other states. The states (2,2), (2,3), and (2,4) are blocked off and cannot be traversed.
	We initialize the value function to be 0 at each state (left), and initialize the policy to be random (right).
	</p>

	<div style="width: 100%; overflow: hidden;">
	    <div style="width: 600px; float: left;"> {{value_table1|safe}} </div>
	    <div style="margin-left: 620px;"> {{policy_table1|safe}} </div>
	</div>

	<p>
	In the first round of policy evaluation step we find the optimal value for each state given the initial policy <img src="http://latex.codecogs.com/gif.latex?\pi^{0}" border="0"/>
	For the first iteration of the policy evaluation step we compute <img src="http://latex.codecogs.com/gif.latex?V_{1}^{\pi^{0}}(s)" border="0"/> as follows:
	<div lang="latex">
	V_{1}^{\pi}^{0}(s) = \sum_{s'}P(s, \pi^{0}(s), s')(R(s, \pi^{0}(s), s') + \gamma V_{0}^{\pi}^{0}(s'))
	</div>
	Since <img src="http://latex.codecogs.com/gif.latex?V_{0}^{\pi^{0}}(s)" border="0"/> was initialized to as 0 for each state, <img src="http://latex.codecogs.com/gif.latex?V_{1}^{\pi^{0}}(s)" border="0"/>
	will be only the immediate reward gained if we follow the policy <img src="http://latex.codecogs.com/gif.latex?\pi^{0}(s)" border="0"/> at each state. For the state (0,0), our policy is to move to the left. Since we are already at the edge of the grid we will stay in the same state and gain a reward of 1. The policy at (3,4) is to go up which where we gain the reward of 1 from (3,3), so the new value at (3,4) is 1. For all other states, the initial policy does not bring us to a stay where we gain any reward, so their values stay at 0.
	</p>

	<div style="width: 100%; overflow: hidden;">
	    <div style="width: 600px; float: left;"> {{intermediate_table|safe}} </div>
	    <div style="margin-left: 620px;"> {{policy_table1|safe}} </div>
	</div>	


	<p>
	We repeat this step for <img src="http://latex.codecogs.com/gif.latex?V_{i+1}^{\pi^{0}}(s)" border="0"/> until the value function converges, meaning that <img src="http://latex.codecogs.com/gif.latex?|V_{i+1}(s) - V_{i}(s)|" border="0"/> is less than some small number for all states (see the example under value iteration for more details). Since we can reach (3,3) from (3,3), (3,4), (4,3) and (4,4) using the policy <img src="http://latex.codecogs.com/gif.latex?\pi^{0}" border="0"/> (try tracing a path using only the moves specified by the policy), each of these states will converge on values greater than 0. For the remainder of the states besides (0,0), we still cannot reach a state with a reward given our current policy so the values at these states remain 0. Next we update the policy by taking the best action at each state given our new value function (right). We can see that the policy at (0,0) has not changed, since continually moving left against the edge still gives us the maximum score. For the states adjacent to either (0,0) or (3,3), the optimal policy is to move in whatever direction that brings us to that state. 
	</p>
	<div style="width: 100%; overflow: hidden;">
	    <div style="width: 600px; float: left;"> {{value_table2|safe}} </div>
	    <div style="margin-left: 620px;"> {{policy_table2|safe}} </div>
	</div>

	<p>
	This process is repeated for <img src="http://latex.codecogs.com/gif.latex?\pi^{1}" border="0"/>: We again update the value function until convergence (left) and optimize the policy (right).
	</p>
	<div style="width: 100%; overflow: hidden;">
	    <div style="width: 600px; float: left;"> {{value_table3|safe}} </div>
	    <div style="margin-left: 620px;"> {{policy_table3|safe}} </div>
	</div>


	<p>
	We repeat these two steps until <img src="http://latex.codecogs.com/gif.latex?\pi^{i+1}=\pi^{i}" border="0"/>, at which point we know the expected reward at each state (left) our policy has converged (right).
	</p>
	<div style="width: 100%; overflow: hidden;">
	    <div style="width: 600px; float: left;"> {{value_table4|safe}} </div>
	    <div style="margin-left: 620px;"> {{policy_table4|safe}} </div>
	</div>

</div>

<div>
<p>
In the environment below, click policy evaluation to perform one step of policy evaluation. You will find that at some point the values represented in each cell will stop changing, indicating that the value function has converged for the current policy. Click policy improvement to update the policy given the current value function. Alternating between these steps, you will find that eventually clicking policy improvement will not cause the policy for any of the states to change, indicating that the algorithm has converged.
</p>
</div>

<div>
	<input type="number" id='discount' step="0.1" value=".8" min="0" max=".99" style="width: 4em"></input>
    <button type="button" id="update_discount" onclick="update_reward(selected_row, selected_col)">update discount</button>
	<input type="number" id='reward' value="0" style="width: 4em" disabled></input>
    <button type="button" id="reward_button" onclick="update_reward(selected_row, selected_col)" disabled>update reward</button>
	<button type="button" id="blocked_button" onclick="toggle_blocked(selected_row, selected_col)"disabled>toggle blocked</button>
	<div id='table'>
		{{table|safe}}
	</div>
	<button type="button" onclick="policy_evaluation_step()">policy evaluation</button>
	<button type="button" onclick="policy_improvement()">policy improvement</button>
	<button type="button" onclick="reset()">reset</button>
</div>

<script type="text/javascript">

	var size = {{size}}
	var state_rewards_list = {{state_rewards_list}}
    var blocked_states_list = {{blocked_states_list}}
    var discount = {{discount}}
    var values = {{values}}
    var policy = {{policy}}

    var original_color = null
	var selected_row = null
	var selected_col = null

	var started = false
	

	$("#table").on('click', 'td', function() {

		document.getElementById("reward").disabled = false;
		document.getElementById("reward_button").disabled = false;
		document.getElementById("blocked_button").disabled = false;

	    var id = $(this).attr("id");
	    selected_row = parseInt(id[0])
	    selected_col = parseInt(id[1])

	    //save original class
	    var cell_class = $(this).attr("class");

	    //deselect other cells
	    var selected = document.getElementsByClassName('selected')
	    if (selected.length > 0){
	    	cell = selected[0]
	    	cell.classList.remove("selected")
	    	cell.style.background = original_color
	    }

	    //if it wasn't selected originally, select cell
	    if (typeof cell_class !== 'selected'){
	    	$(this).addClass('selected')
	    	original_color = $(this).css('background-color')
	    	$( this ).css( 'background-color', 'yellow' );
	    }

	});


	function update_discount(selected_row, selected_col){

		var discount = parseInt(document.getElementById('discount').value)
		state_rewards_list.push([[selected_row, selected_col], discount])
		update_table('/update');
	}


	function update_reward(selected_row, selected_col){

		var reward = parseInt(document.getElementById('reward').value)
		state_rewards_list.push([[selected_row, selected_col], reward])
		update_table('/update');
	}


	function is_blocked(cell){

		var idx = -1
		for (var i=0; i<blocked_states_list.length; i++){
			if (cell[0] == blocked_states_list[i][0] & cell[1] == blocked_states_list[i][1]){
				idx = i
			}
		}
		return idx
	}

	function toggle_blocked(selected_row, selected_col){

		var cell = [selected_row, selected_col]
		idx = is_blocked(cell)

		if (idx == -1){
			blocked_states_list.push(cell)
		} else {
			blocked_states_list.splice(idx, 1)
		}
		update_table('/update');
	}

	function update_table(url){

		data = {"size": size,
	    		  "state_rewards_list": state_rewards_list,
	    		  "blocked_states_list": blocked_states_list,
	    		  "discount": discount,
	    		  "values": values,
	    		  "policy": policy,
	    		  "started": started}

		$.ajax({
	        method:"POST",
	        contentType: 'application/json',
	        url: url,
	        data:JSON.stringify(data),
	    	dataType: 'json',
          	contentType: 'application/json; charset=utf-8',
	        success:function(resp, data){
	            var response = resp;
	            var table = response['table']
	            document.getElementById("table").innerHTML = table
	            values = response['values']
	            policy = response['policy']
	        },
	    });
	}


	function policy_evaluation_step(){

		update_table("/policy_evaluation_step")
		started = true
	}


	function policy_improvement(){

		update_table("/policy_improvement")
	}


	function reset(){

		started = false
		update_table("/update")
	}


</script>


<style type="text/css">
	
	td {
	    border: 1px solid;
	    width: 50px;
	    height: 50px;
	}

</style>

</html>